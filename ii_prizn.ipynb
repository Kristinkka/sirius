{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import nltk\n", "import json\n", "import string"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nltk.download('stopwords')\n", "nltk.download('punkt')\n", "from nltk.tokenize import word_tokenize\n", "from nltk.corpus import stopwords\n", "from nltk.stem.snowball import SnowballStemmer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = json.load(open(\"res.json\", \"r\", encoding=\"utf-8\"))\n", "res = []\n", "for review in data:\n", "    text = review[0]\n", "    word_tokens = word_tokenize(text)\n", "    stemmer = SnowballStemmer(\"russian\")\n", "    \n", "    stop_words = set(stopwords.words('russian'))\n", "    filtered_tokens = [word for word in word_tokens if word not in stop_words]\n", "    stemmed_words = [stemmer.stem(word) for word in filtered_tokens if word not in string.punctuation]\n", "    res.append([stemmed_words, review[1]])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["clean_reviews = res"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}